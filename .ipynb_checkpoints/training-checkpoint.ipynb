{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c82c677a-b9f9-4a14-b937-6d69e63687c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbb34d0c428745eba87d7003a26ceb3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:  15%|#4        | 105M/714M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc72252065054589bd20f73c900acd84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/714M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForMaskedLM\n",
    "from datasets import load_dataset, load_from_disk\n",
    "import re\n",
    "import torch\n",
    "\n",
    "model_name = \"DeepPavlov/rubert-base-cased\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertForMaskedLM.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1706be57-964b-415a-ad78-655a0059d563",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b13cf26ebbed4dda9006dfa305bdc19c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "raw_datasets = load_dataset(\"json\", data_files=\"data/processed/data.jsonl\")\n",
    "\n",
    "tokenizer.add_special_tokens({\"additional_special_tokens\": [\"[TGT]\", \"[/TGT]\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "359d9b32-5133-4138-824f-f7285d1d706d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab404929949843269c4398b8353e7b8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9110 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocess_batch(batch):\n",
    "    enc = tokenizer(\n",
    "        batch[\"text\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=128,\n",
    "    )\n",
    "    batch[\"input_ids\"]      = enc[\"input_ids\"]\n",
    "    batch[\"attention_mask\"] = enc[\"attention_mask\"]\n",
    "\n",
    "    labels = []\n",
    "    for input_ids, target in zip(enc[\"input_ids\"], batch[\"target\"]):\n",
    "        target_ids = tokenizer(target, add_special_tokens=False)[\"input_ids\"]\n",
    "        lbl = [-100] * len(input_ids)\n",
    "        pos = input_ids.index(tokenizer.mask_token_id)\n",
    "        for i, tid in enumerate(target_ids):\n",
    "            if pos + i < len(lbl):\n",
    "                lbl[pos + i] = tid\n",
    "        labels.append(lbl)\n",
    "    batch[\"labels\"] = labels\n",
    "    return batch\n",
    "\n",
    "tokenized = raw_datasets.map(preprocess_batch, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd05f7e5-5bc4-4c7c-aede-b9de2192f629",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized.save_to_disk(\"data/processed/tokenized_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20a981af-51b9-483d-80b1-ce5d6ff2957c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "tokenized = load_from_disk(\"data/processed/tokenized_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c605d6d8-52e9-4fcf-8b7f-de68ce20aeb1",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AutoModelForMaskedLM, DataCollatorForLanguageModeling\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresize_token_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m data_collator = DataCollatorForLanguageModeling(\n\u001b[32m      6\u001b[39m     tokenizer=tokenizer,\n\u001b[32m      7\u001b[39m     mlm=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m      8\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Документы\\ВУЗ\\ML\\model-training\\bert-env\\Lib\\site-packages\\transformers\\modeling_utils.py:2656\u001b[39m, in \u001b[36mPreTrainedModel.resize_token_embeddings\u001b[39m\u001b[34m(self, new_num_tokens, pad_to_multiple_of, mean_resizing)\u001b[39m\n\u001b[32m   2620\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mresize_token_embeddings\u001b[39m(\n\u001b[32m   2621\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   2622\u001b[39m     new_num_tokens: Optional[\u001b[38;5;28mint\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   2623\u001b[39m     pad_to_multiple_of: Optional[\u001b[38;5;28mint\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   2624\u001b[39m     mean_resizing: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m   2625\u001b[39m ) -> nn.Embedding:\n\u001b[32m   2626\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2627\u001b[39m \u001b[33;03m    Resizes input token embeddings matrix of the model if `new_num_tokens != config.vocab_size`.\u001b[39;00m\n\u001b[32m   2628\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   2654\u001b[39m \u001b[33;03m        `torch.nn.Embedding`: Pointer to the input tokens Embeddings Module of the model.\u001b[39;00m\n\u001b[32m   2655\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2656\u001b[39m     model_embeds = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_resize_token_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_num_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean_resizing\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2657\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m new_num_tokens \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m pad_to_multiple_of \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2658\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m model_embeds\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Документы\\ВУЗ\\ML\\model-training\\bert-env\\Lib\\site-packages\\transformers\\modeling_utils.py:2679\u001b[39m, in \u001b[36mPreTrainedModel._resize_token_embeddings\u001b[39m\u001b[34m(self, new_num_tokens, pad_to_multiple_of, mean_resizing)\u001b[39m\n\u001b[32m   2677\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_resize_token_embeddings\u001b[39m(\u001b[38;5;28mself\u001b[39m, new_num_tokens, pad_to_multiple_of=\u001b[38;5;28;01mNone\u001b[39;00m, mean_resizing=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m   2678\u001b[39m     old_embeddings = \u001b[38;5;28mself\u001b[39m.get_input_embeddings()\n\u001b[32m-> \u001b[39m\u001b[32m2679\u001b[39m     new_embeddings = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_resized_embeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2680\u001b[39m \u001b[43m        \u001b[49m\u001b[43mold_embeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_num_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean_resizing\u001b[49m\n\u001b[32m   2681\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2682\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(old_embeddings, \u001b[33m\"\u001b[39m\u001b[33m_hf_hook\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m   2683\u001b[39m         hook = old_embeddings._hf_hook\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Документы\\ВУЗ\\ML\\model-training\\bert-env\\Lib\\site-packages\\transformers\\modeling_utils.py:2802\u001b[39m, in \u001b[36mPreTrainedModel._get_resized_embeddings\u001b[39m\u001b[34m(self, old_embeddings, new_num_tokens, pad_to_multiple_of, mean_resizing)\u001b[39m\n\u001b[32m   2790\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m   2791\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mOld embeddings are of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(old_embeddings)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, which is not an instance of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnn.Embedding\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. You\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2792\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m should either use a different resize function or make sure that `old_embeddings` are an instance of\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2793\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnn.Embedding\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2794\u001b[39m     )\n\u001b[32m   2796\u001b[39m \u001b[38;5;66;03m# Build new embeddings\u001b[39;00m\n\u001b[32m   2797\u001b[39m \n\u001b[32m   2798\u001b[39m \u001b[38;5;66;03m# When using DeepSpeed ZeRO-3, we shouldn't create new embeddings with DeepSpeed init\u001b[39;00m\n\u001b[32m   2799\u001b[39m \u001b[38;5;66;03m# because the shape of the new embedding layer is used across various modeling files\u001b[39;00m\n\u001b[32m   2800\u001b[39m \u001b[38;5;66;03m# as well as to update config vocab size. Shape will be 0 when using DeepSpeed init leading\u001b[39;00m\n\u001b[32m   2801\u001b[39m \u001b[38;5;66;03m# to errors when training.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2802\u001b[39m new_embeddings = \u001b[43mnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmbedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2803\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnew_num_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2804\u001b[39m \u001b[43m    \u001b[49m\u001b[43mold_embedding_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2805\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mold_embeddings\u001b[49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2806\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mold_embeddings\u001b[49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2807\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2809\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m new_num_tokens > old_num_tokens \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mean_resizing:\n\u001b[32m   2810\u001b[39m     \u001b[38;5;66;03m# initialize new embeddings (in particular added tokens) with a mean of 0 and std equals `config.initializer_range`.\u001b[39;00m\n\u001b[32m   2811\u001b[39m     \u001b[38;5;28mself\u001b[39m._init_weights(new_embeddings)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Документы\\ВУЗ\\ML\\model-training\\bert-env\\Lib\\site-packages\\torch\\nn\\modules\\sparse.py:167\u001b[39m, in \u001b[36mEmbedding.__init__\u001b[39m\u001b[34m(self, num_embeddings, embedding_dim, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse, _weight, _freeze, device, dtype)\u001b[39m\n\u001b[32m    164\u001b[39m \u001b[38;5;28mself\u001b[39m.scale_grad_by_freq = scale_grad_by_freq\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    166\u001b[39m     \u001b[38;5;28mself\u001b[39m.weight = Parameter(\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m         \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_embeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_dim\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfactory_kwargs\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m    168\u001b[39m         requires_grad=\u001b[38;5;129;01mnot\u001b[39;00m _freeze,\n\u001b[32m    169\u001b[39m     )\n\u001b[32m    170\u001b[39m     \u001b[38;5;28mself\u001b[39m.reset_parameters()\n\u001b[32m    171\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mRuntimeError\u001b[39m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForMaskedLM, DataCollatorForLanguageModeling\n",
    "\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57eb696e-087d-4f37-9a52-fc09fb975d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Меняем директории кэширования\n",
    "os.environ[\"HF_HOME\"] = \"D:/hf\"\n",
    "os.environ[\"HF_DATASETS_CACHE\"] = \"D:/hf/datasets\"\n",
    "os.environ[\"TRANSFORMERS_CACHE\"] = \"D:/hf/transformers\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "057bcbaa-782a-459d-9642-529c9c395d9e",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TrainingArguments, Trainer\n\u001b[32m      3\u001b[39m training_args = TrainingArguments(\n\u001b[32m      4\u001b[39m     output_dir=\u001b[33m\"\u001b[39m\u001b[33m./bert-artistic\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      5\u001b[39m     num_train_epochs=\u001b[32m3\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m      9\u001b[39m     save_total_limit=\u001b[32m2\u001b[39m,\n\u001b[32m     10\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m trainer = \u001b[43mTrainer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtraining_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtokenized\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtrain\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata_collator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_collator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m trainer.train()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Документы\\ВУЗ\\ML\\model-training\\bert-env\\Lib\\site-packages\\transformers\\utils\\deprecation.py:172\u001b[39m, in \u001b[36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action.NOTIFY, Action.NOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[32m    170\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Документы\\ВУЗ\\ML\\model-training\\bert-env\\Lib\\site-packages\\transformers\\trainer.py:457\u001b[39m, in \u001b[36mTrainer.__init__\u001b[39m\u001b[34m(self, model, args, data_collator, train_dataset, eval_dataset, processing_class, model_init, compute_loss_func, compute_metrics, callbacks, optimizers, optimizer_cls_and_kwargs, preprocess_logits_for_metrics)\u001b[39m\n\u001b[32m    455\u001b[39m \u001b[38;5;28mself\u001b[39m.compute_loss_func = compute_loss_func\n\u001b[32m    456\u001b[39m \u001b[38;5;66;03m# Seed must be set before instantiating the model when using model\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m457\u001b[39m enable_full_determinism(\u001b[38;5;28mself\u001b[39m.args.seed) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.full_determinism \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mset_seed\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    459\u001b[39m \u001b[38;5;28mself\u001b[39m.hp_name = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    460\u001b[39m \u001b[38;5;28mself\u001b[39m.deepspeed = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Документы\\ВУЗ\\ML\\model-training\\bert-env\\Lib\\site-packages\\transformers\\trainer_utils.py:105\u001b[39m, in \u001b[36mset_seed\u001b[39m\u001b[34m(seed, deterministic)\u001b[39m\n\u001b[32m    103\u001b[39m np.random.seed(seed)\n\u001b[32m    104\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_torch_available():\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m     \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmanual_seed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    106\u001b[39m     torch.cuda.manual_seed_all(seed)\n\u001b[32m    107\u001b[39m     \u001b[38;5;66;03m# ^^ safe to call this function even if cuda is not available\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Документы\\ВУЗ\\ML\\model-training\\bert-env\\Lib\\site-packages\\torch\\_compile.py:51\u001b[39m, in \u001b[36m_disable_dynamo.<locals>.inner\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     48\u001b[39m     disable_fn = torch._dynamo.disable(fn, recursive)\n\u001b[32m     49\u001b[39m     fn.__dynamo_disable = disable_fn  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdisable_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Документы\\ВУЗ\\ML\\model-training\\bert-env\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:838\u001b[39m, in \u001b[36mDisableContext.__call__.<locals>._fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    836\u001b[39m _maybe_set_eval_frame(_callback_from_stance(\u001b[38;5;28mself\u001b[39m.callback))\n\u001b[32m    837\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m838\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    839\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    840\u001b[39m     set_eval_frame(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Документы\\ВУЗ\\ML\\model-training\\bert-env\\Lib\\site-packages\\torch\\random.py:46\u001b[39m, in \u001b[36mmanual_seed\u001b[39m\u001b[34m(seed)\u001b[39m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcuda\u001b[39;00m\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch.cuda._is_in_bad_fork():\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m     \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcuda\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmanual_seed_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmps\u001b[39;00m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch.mps._is_in_bad_fork():\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Документы\\ВУЗ\\ML\\model-training\\bert-env\\Lib\\site-packages\\torch\\cuda\\random.py:128\u001b[39m, in \u001b[36mmanual_seed_all\u001b[39m\u001b[34m(seed)\u001b[39m\n\u001b[32m    125\u001b[39m         default_generator = torch.cuda.default_generators[i]\n\u001b[32m    126\u001b[39m         default_generator.manual_seed(seed)\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m \u001b[43m_lazy_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed_all\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Документы\\ВУЗ\\ML\\model-training\\bert-env\\Lib\\site-packages\\torch\\cuda\\__init__.py:302\u001b[39m, in \u001b[36m_lazy_call\u001b[39m\u001b[34m(callable, **kwargs)\u001b[39m\n\u001b[32m    300\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m _initialization_lock:\n\u001b[32m    301\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_initialized():\n\u001b[32m--> \u001b[39m\u001b[32m302\u001b[39m         \u001b[38;5;28;43mcallable\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    303\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    304\u001b[39m         \u001b[38;5;66;03m# TODO(torch_deploy): this accesses linecache, which attempts to read the\u001b[39;00m\n\u001b[32m    305\u001b[39m         \u001b[38;5;66;03m# file system to get traceback info. Patch linecache or do something\u001b[39;00m\n\u001b[32m    306\u001b[39m         \u001b[38;5;66;03m# else here if this ends up being important.\u001b[39;00m\n\u001b[32m    307\u001b[39m         \u001b[38;5;28;01mglobal\u001b[39;00m _lazy_seed_tracker\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Документы\\ВУЗ\\ML\\model-training\\bert-env\\Lib\\site-packages\\torch\\cuda\\random.py:126\u001b[39m, in \u001b[36mmanual_seed_all.<locals>.cb\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(device_count()):\n\u001b[32m    125\u001b[39m     default_generator = torch.cuda.default_generators[i]\n\u001b[32m--> \u001b[39m\u001b[32m126\u001b[39m     \u001b[43mdefault_generator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmanual_seed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./bert-artistic\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    logging_steps=100,\n",
    "    save_steps=500,\n",
    "    save_total_limit=2,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized[\"train\"],\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9807255-c501-4024-ba08-014193205449",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
