{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddfcab6-689c-45ed-bb49-7679a48e9251",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForMaskedLM\n",
    "import torch\n",
    "\n",
    "model_name = \"DeepPavlov/rubert-base-cased\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertForMaskedLM.from_pretrained(model_name)\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aaedf81f-6602-4709-ab7b-c1763d3f304c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_mask(text, top_k=5):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "    mask_token_index = torch.where(inputs[\"input_ids\"] == tokenizer.mask_token_id)[1]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    logits = outputs.logits\n",
    "    mask_token_logits = logits[0, mask_token_index, :]\n",
    "    top_tokens = torch.topk(mask_token_logits, top_k, dim=1).indices[0].tolist()\n",
    "\n",
    "    return [tokenizer.decode([token]).strip() for token in top_tokens]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "919a79b2-9b63-4fe5-9686-fc524222be80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def predict_synonym_in_context(sentence, target_word, top_k=5):\n",
    "    # Заменяем первое вхождение слова на [MASK]\n",
    "    pattern = rf\"\\b{re.escape(target_word)}\\b\"\n",
    "    masked_sentence = re.sub(pattern, tokenizer.mask_token, sentence, count=1)\n",
    "\n",
    "    if tokenizer.mask_token not in masked_sentence:\n",
    "        raise ValueError(\"Слово для замены не найдено в предложении.\")\n",
    "\n",
    "    print(\"С предложением:\", masked_sentence)\n",
    "    return predict_mask(masked_sentence, top_k=top_k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d11354e0-0290-4565-af5c-5268a7d12956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "С предложением: Он громко [MASK] и ушёл.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['кричал', 'встал', 'поднялся', 'сказал', 'пошутил']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_synonym_in_context(\"Он громко сказал и ушёл.\", \"сказал\", top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8441ab3-255a-416d-81c9-3dcb497b0e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_contextual_insert(masked_sentence, top_k=5):\n",
    "    if tokenizer.mask_token not in masked_sentence:\n",
    "        raise ValueError(\"В предложении должен быть [MASK].\")\n",
    "\n",
    "    print(\"С предложением:\", masked_sentence)\n",
    "    return predict_mask(masked_sentence, top_k=top_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c01a4155-7f9e-4d12-a131-1974bad4c79b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "С предложением: Он [MASK] бежал.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['также', 'немедленно', 'тоже', 'не', 'снова']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_contextual_insert(\"Он [MASK] бежал.\", top_k=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
