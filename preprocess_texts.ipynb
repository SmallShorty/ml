{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07360492-fe01-4dca-82cd-9efef530cf7a",
   "metadata": {},
   "source": [
    "Выбранные произведения\n",
    "\n",
    "М. Горький – \"Мать\" (gorky_mat.txt): насыщенный эмоциональный текст, подходит для анализа эпитетов и наречий.\n",
    "\n",
    "А. Куприн – \"Яма\" (kuprin_yama.txt): реалистичное описание, богатое на прилагательные и наречия.\n",
    "\n",
    "И. Бунин – \"Деревня\" (bunin_derevnya.txt): короткий роман с выразительным языком.\n",
    "\n",
    "Н. Лесков – \"Левша\" (leskov_levsha.txt): насыщенный художественный язык, множество прилагательных.\n",
    "\n",
    "А. Чехов – \"Палата №6\" (chekhov_palata_no_6.txt): компактное произведение, подходящее для быстрой обработки.\n",
    "\n",
    "И. Тургенев – \"Отцы и дети\" (turgenev_otcy_i_deti.txt): классический роман с разнообразным словарным запасом.\n",
    "\n",
    "Ф. Достоевский – \"Идиот\" (dostoevsky_idiot.txt): глубокий психологический роман, полезен для анализа сложных конструкций.\n",
    "\n",
    "Л. Толстой – \"Анна Каренина\" (tolstoy_anna_karenina.txt): обширный роман, можно использовать выборочно для анализа."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8c1144e-930d-420c-8d6a-83ca7d991a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_LIST = [\n",
    "    \"Bulgakov_Master.txt\",\n",
    "    \"Bulgakov_ZapiskiYonogoVracha.txt\",\n",
    "    \"Gorky_ZyznKlimaSamgina1.txt\",\n",
    "    \"Gorky_ZyznKlimaSamgina2.txt\",\n",
    "    \"Gorky_ZyznKlimaSamgina3.txt\",\n",
    "    \"Gorky_ZyznKlimaSamgina4.txt\",\n",
    "    \"Nabokov_Dar_1938.txt\",\n",
    "    \"Nabokov_Podvig_1932.txt\",\n",
    "    \"Nabokov_Zashchita_1930.txt\",\n",
    "    \"Sologub_MelkijBes.txt\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b020b4f-0882-4d8a-b53e-69ec9b4ecf67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "\n",
    "RAW_DIR = \"RussianNovels/corpus\"\n",
    "CLEAN_DIR = \"data/clean\"\n",
    "os.makedirs(CLEAN_DIR, exist_ok=True)\n",
    "\n",
    "def clean_text(text: str) -> str:\n",
    "    text = re.sub(r'\\ufeff', '', text)\n",
    "    text = re.sub(r'\\r\\n?', '\\n', text)\n",
    "    text = re.sub(r'[ \\t]+', ' ', text) \n",
    "    text = re.sub(r'\\n{2,}', '\\n', text)\n",
    "    text = text.lower() \n",
    "    return text.strip()\n",
    "\n",
    "for filename in os.listdir(RAW_DIR):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        path = os.path.join(RAW_DIR, filename)\n",
    "        with open(path, encoding='utf-8') as f:\n",
    "            raw = f.read()\n",
    "        cleaned = clean_text(raw)\n",
    "        out_path = os.path.join(CLEAN_DIR, filename)\n",
    "        with open(out_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(cleaned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "988bb565-a4b2-4c39-a676-408be923d286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загружаем модель spaCy...\n",
      "Модель загружена.\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "print(\"Загружаем модель spaCy...\")\n",
    "nlp = spacy.load(\"ru_core_news_lg\")\n",
    "print(\"Модель загружена.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd0432a2-5a57-4757-b8af-4f28ba352f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def has_descriptive_language(sentence):\n",
    "    adj_adv_count = sum(1 for token in sentence if token.pos_ in ['ADJ', 'ADV'])\n",
    "    return adj_adv_count >= 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7919ad7-63a1-40de-812f-c8fcba91037e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def is_dialogue(sentence):\n",
    "    text = sentence.text.strip()\n",
    "    return text.startswith(\"—\") or text.startswith(\"--\") or re.match(r'[\"«].+[\"»]', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e4f626d-cf36-4afe-9922-f8c92d00a207",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_meaningful(sent, min_len=12, max_len=18):\n",
    "    content_words = [token for token in sent if token.pos_ in {\"NOUN\", \"PROPN\", \"VERB\", \"AUX\", \"ADJ\", \"ADV\"}]\n",
    "    return min_len <= len(content_words) <= max_len\n",
    "\n",
    "def preprocess_text(text: str):\n",
    "    lines = text.splitlines()\n",
    "    cleaned_lines = []\n",
    "    buffer = \"\"\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        if line.startswith(\"--\"):\n",
    "            if buffer:\n",
    "                cleaned_lines.append(buffer.strip())\n",
    "                buffer = \"\"\n",
    "            cleaned_lines.append(line)\n",
    "        else:\n",
    "            if line.endswith(\"...\") or line.endswith(\".\") or line.endswith(\"?\") or line.endswith(\"!\"):\n",
    "                buffer += \" \" + line\n",
    "                cleaned_lines.append(buffer.strip())\n",
    "                buffer = \"\"\n",
    "            else:\n",
    "                buffer += \" \" + line\n",
    "\n",
    "    if buffer:\n",
    "        cleaned_lines.append(buffer.strip())\n",
    "\n",
    "    return cleaned_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e2a71c0-4c7f-49af-aac4-22402306a02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nlp.Defaults.stop_words\n",
    "def remove_stopwords_from_spacy_doc(doc, stopwords):\n",
    "    tokens = [token.text for token in doc if token.text.lower() not in stopwords and not token.is_punct]\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0add032d-b696-4823-b3df-75b7352ac131",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import spacy\n",
    "\n",
    "def segment_and_filter(\n",
    "    path: str,\n",
    "    min_len: int = 12,\n",
    "    max_len: int = 18,\n",
    "    out_dir: str = \"data/filtered\"\n",
    "):\n",
    "    print(f\"Чтение файла: {path}\")\n",
    "    with open(path, encoding='utf-8') as f:\n",
    "        raw_text = f.read()\n",
    "\n",
    "    print(\"Предобработка строк...\")\n",
    "    lines = preprocess_text(raw_text)\n",
    "\n",
    "    sentences = []\n",
    "    print(\"Анализ предложений spaCy и фильтрация...\")\n",
    "    for line in lines:\n",
    "        doc = nlp(line)\n",
    "        for sent in doc.sents:\n",
    "            cleaned_text = remove_stopwords_from_spacy_doc(sent, stopwords)\n",
    "            if not cleaned_text.strip():\n",
    "                continue\n",
    "            cleaned_doc = nlp(cleaned_text)\n",
    "    \n",
    "            if is_dialogue(cleaned_doc):\n",
    "                continue\n",
    "            if not is_meaningful(cleaned_doc, min_len, max_len):\n",
    "                continue\n",
    "            if not has_descriptive_language(cleaned_doc):\n",
    "                continue\n",
    "\n",
    "        sentences.append(cleaned_text)\n",
    "\n",
    "    print(f\"Подходящих предложений найдено: {len(sentences)}\")\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    filename = os.path.basename(path)\n",
    "    out_path = os.path.join(out_dir, filename)\n",
    "\n",
    "    with open(out_path, 'w', encoding='utf-8') as f_out:\n",
    "        for s in sentences:\n",
    "            f_out.write(s + '\\n')\n",
    "\n",
    "    print(f\"Результат сохранён в: {out_path}\")\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62cf70d3-368a-46b0-a6c5-a4ce44b2b9ab",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'FILE_LIST' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m TEXT_DIR = \u001b[33m\"\u001b[39m\u001b[33mdata/clean\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      2\u001b[39m OUT_DIR = \u001b[33m\"\u001b[39m\u001b[33mdata/filtered\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m \u001b[43mFILE_LIST\u001b[49m:\n\u001b[32m      5\u001b[39m     path = os.path.join(TEXT_DIR, filename)\n\u001b[32m      6\u001b[39m     segment_and_filter(path, out_dir=OUT_DIR)\n",
      "\u001b[31mNameError\u001b[39m: name 'FILE_LIST' is not defined"
     ]
    }
   ],
   "source": [
    "TEXT_DIR = \"data/clean\"\n",
    "OUT_DIR = \"data/filtered\"\n",
    "\n",
    "for filename in FILE_LIST:\n",
    "    path = os.path.join(TEXT_DIR, filename)\n",
    "    segment_and_filter(path, out_dir=OUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e56880c-8803-4807-b344-441d46b1902a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Чтение файла: data/clean\\Bulgakov_BelayaGvardiya.txt\n",
      "Предобработка строк...\n",
      "Анализ предложений spaCy и фильтрация...\n"
     ]
    }
   ],
   "source": [
    "TEXT_DIR = \"data/clean\"\n",
    "OUT_DIR = \"data/filtered\"\n",
    "\n",
    "for filename in os.listdir(TEXT_DIR):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        path = os.path.join(TEXT_DIR, filename)\n",
    "        segment_and_filter(path, out_dir=OUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9486c5-fa9e-4998-ba38-4726f5150f86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
